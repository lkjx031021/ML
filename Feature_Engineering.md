## 样本不均衡的常用处理办法

- 假定样本数目A类比B类多，且严重失衡：
  - A类欠采样Undersampling
    - 随机欠采样
    - A类分成若干子集，分别与B类进行训练
    - 基于聚类的A类分割
  - B类过采样Oversampling
    - 避免欠采样造成的信息丢失
  - B类数据合成 Synthetic Data Generation
    - 随机插值得到新样本$(\frac{x_1^{(i)}+x_2^{(i)}}{2},\frac{x_1^{(j)}+x_2^{(j)}}{2})$
    - SMOTE（Synthetic Minority Over-sampling Technique）
  - 代价敏感学习 Cost Sensitive Learning
    - 降低A类权值，提高B类权值

## 利用随机森林建立计算样本相似度

原理：若两样本同时出现在相同的叶节点的次数越多，则二者越相似。

算法过程：

​		记样本个数为$N$，初始化$N × N$的零矩阵$S$，$S[i,j]$表示样本$i$和样本$j$的相似度。

​		对于m颗决策树形成的随机森林，遍历所有决策树的所有叶子节点：

​				记该叶子节点包含的样本为$sample[1,2,3,...,k]$，则$S[i][j]$累加1。

​					样本$i,j\in sample[1,2,\cdots,k]$

​					样本$i, j$出现在相同叶子节点的次数增加1次。

​		遍历结束，则S为样本间的相似度矩阵，形如
$$
\begin{array}{c|c}
 & \text{1} & \text{2} & \text{3} \\
\hline
\text{1} & 3 & 2 & 0 \\
\text{2} & 2 & 3 & 1 \\
\text{3} & 0 & 1 & 3 
\end{array}
$$


其中，每一行可以当作一个样本的特征向量，可以利用余弦相似度，欧氏距离，皮尔逊系数等多种方法计算样本相似度。

## 利用随机森林计算特征重要程度

出现次数越多特征越重要



## PCA

1. 计算协方差矩阵
2. 求解协方差矩阵特征值和特征向量
3. 去除比较小的特征值对应的特征向量