## 统计词频（Count-Vector）

```
import sklearn.feature_extraction.text as t2v

text = ['纽约市 初步  初步 迹象 显示 初步',
        '初步 迹象 显示 这是 蓄意',
        '也 无 明确 证据 显示 迹象']
vectorizer = t2v.CountVectorizer()
vectors = vectorizer.fit_transform(text)
# print("单词向量:\n", vectors) 稀疏矩阵
print("单词向量:\n", vectors.todense())
print("字典", vectorizer.vocabulary_)
```

输出结果：

```
单词向量:
 [[3 0 1 1 0 0 0 1]
 [1 0 1 0 1 0 1 1]
 [0 1 1 0 0 1 0 1]]
字典 {'纽约市': 3, '初步': 0, '迹象': 7, '显示': 2, '这是': 6, '蓄意': 4, '明确': 1, '证据': 5}
```

字典含义：单词在向量中的索引

向量含义： 每个位置的词出现的次数

例：  第一个向量[3 0 1 1 0 0 0 1]   ‘初步’这个词在第一篇文章中出现了3次， ‘显示’出现了一次...



## Tf-idf（Term Frequency - Inverse Document Frequency）

即：词频-逆文本频率



$tf-idf=P(w_1)\log \frac{D}{D_{w_1}}$

$P(w_1)$：单词$w_1$在该文章中出现的次数除以该文章的单词总数

$\log\frac{D}{D_{w_1}}$：D 代表数据集中的文章总数，$D_{w_1}$代表包含单词$w_1$的文章数量

因为某些生僻字可能在训练集中没有，所以会出现$D_{w_1}$为0的情况，需要平滑处理：

$\log \frac{D+1}{D_{w_1}+1}$



## LDA

LDA的副产品，文档 主题频率作为向量



## Word2Vector





# NLP库

- gensim
- 英文： NLTK
- 中文：HanLP、snownLP
- jieba