解决过拟合：

根本方式是增加训练集



### 集成学习

- Bagging：将多个模型的结果直接平均
  - 将一些列容易过拟合的模型做平均
  - 容易过拟合的分类器：高反差，低偏差
  - 容易欠拟合的分类器：低方差，高偏差
  - 随机森林

- Boosting：将多个容易欠拟合的模型加权平均
  - 广度神经网络
  - Adaboost





神经网络权值修剪（剪枝）通过设置阈值的方式进行，如：将权值小于$10^{-3}$的全参数直接置为0



最大后验估计相当于在最大似然估计上加了正则化